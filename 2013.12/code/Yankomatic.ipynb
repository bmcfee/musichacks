{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import BeautifulSoup\n",
      "import urllib2\n",
      "from pprint import pprint\n",
      "import cPickle as pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 300
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 0. Syllable analysize, from p2tk\n",
      "English = {\n",
      "\t'consonants': ['B', 'CH', 'D', 'DH', 'F', 'G', 'HH', 'JH', 'K', 'L', 'M', 'N', \n",
      "\t'NG', 'P', 'R', 'S', 'SH', 'T', 'TH', 'V', 'W', 'Y', 'Z', 'ZH'],\n",
      "\t'vowels': [ 'AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', 'IH', 'IY', 'OW', 'OY', 'UH', 'UW'],\n",
      "\t'onsets': ['P', 'T', 'K', 'B', 'D', 'G', 'F', 'V', 'TH', 'DH', 'S', 'Z', 'SH', 'CH', 'JH', 'M',\n",
      "\t'N', 'R', 'L', 'HH', 'W', 'Y', 'P R', 'T R', 'K R', 'B R', 'D R', 'G R', 'F R',\n",
      "\t'TH R', 'SH R', 'P L', 'K L', 'B L', 'G L', 'F L', 'S L', 'T W', 'K W', 'D W', \n",
      "\t'S W', 'S P', 'S T', 'S K', 'S F', 'S M', 'S N', 'G W', 'SH W', 'S P R', 'S P L',\n",
      "\t'S T R', 'S K R', 'S K W', 'S K L', 'TH W', 'ZH', 'P Y', 'K Y', 'B Y', 'F Y', \n",
      "\t'HH Y', 'V Y', 'TH Y', 'M Y', 'S P Y', 'S K Y', 'G Y', 'HH W', '']\n",
      "}\n",
      "\n",
      "def syllabify(language, word) :\n",
      "\t'''Syllabifies the word, given a language configuration loaded with loadLanguage.\n",
      "\t   word is either a string of phonemes from the CMU pronouncing dictionary set\n",
      "\t   (with optional stress numbers after vowels), or a Python list of phonemes,\n",
      "\t   e.g. \"B AE1 T\" or [\"B\", \"AE1\", \"T\"]'''\n",
      "\t   \n",
      "\tif type(word) == str :\n",
      "\t\tword = word.split()\n",
      "\t\t\n",
      "\tsyllables = [] # This is the returned data structure.\n",
      "\n",
      "\tinternuclei = [] # This maintains a list of phonemes between nuclei.\n",
      "\t\n",
      "\tfor phoneme in word :\n",
      "\t\n",
      "\t\tphoneme = phoneme.strip()\n",
      "\t\tif phoneme == \"\" :\n",
      "\t\t\tcontinue\n",
      "\t\tstress = None\n",
      "\t\tif phoneme[-1].isdigit() :\n",
      "\t\t\tstress = int(phoneme[-1])\n",
      "\t\t\tphoneme = phoneme[0:-1]\n",
      "\t\t\n",
      "\t\tif phoneme in language[\"vowels\"] :\n",
      "\t\t\t# Split the consonants seen since the last nucleus into coda and onset.\n",
      "\t\t\t\n",
      "\t\t\tcoda = None\n",
      "\t\t\tonset = None\n",
      "\t\t\t\n",
      "\t\t\t# If there is a period in the input, split there.\n",
      "\t\t\tif \".\" in internuclei :\n",
      "\t\t\t\tperiod = internuclei.index(\".\")\n",
      "\t\t\t\tcoda = internuclei[:period]\n",
      "\t\t\t\tonset = internuclei[period+1:]\n",
      "\t\t\t\n",
      "\t\t\telse :\n",
      "\t\t\t\t# Make the largest onset we can. The 'split' variable marks the break point.\n",
      "\t\t\t\tfor split in range(0, len(internuclei)+1) :\n",
      "\t\t\t\t\tcoda = internuclei[:split]\n",
      "\t\t\t\t\tonset = internuclei[split:]\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t# If we are looking at a valid onset, or if we're at the start of the word\n",
      "\t\t\t\t\t# (in which case an invalid onset is better than a coda that doesn't follow\n",
      "\t\t\t\t\t# a nucleus), or if we've gone through all of the onsets and we didn't find\n",
      "\t\t\t\t\t# any that are valid, then split the nonvowels we've seen at this location.\n",
      "\t\t\t\t\tif \" \".join(onset) in language[\"onsets\"] \\\n",
      "\t\t\t\t\t   or len(syllables) == 0 \\\n",
      "\t\t\t\t\t   or len(onset) == 0 :\n",
      "\t\t\t\t\t   break\n",
      "\t\t\t   \n",
      "\t\t\t# Tack the coda onto the coda of the last syllable. Can't do it if this\n",
      "\t\t\t# is the first syllable.\n",
      "\t\t\tif len(syllables) > 0 :\n",
      "\t\t\t\tsyllables[-1][3].extend(coda)\n",
      "\t\t\t\n",
      "\t\t\t# Make a new syllable out of the onset and nucleus.\n",
      "\t\t\tsyllables.append( (stress, onset, [phoneme], []) )\n",
      "\t\t\t\t\n",
      "\t\t\t# At this point we've processed the internuclei list.\n",
      "\t\t\tinternuclei = []\n",
      "\n",
      "\t\telif not phoneme in language[\"consonants\"] and phoneme != \".\" :\n",
      "\t\t\traise ValueError, \"Invalid phoneme: \" + phoneme\n",
      "\t\t\t\n",
      "\t\telse : # a consonant\n",
      "\t\t\tinternuclei.append(phoneme)\n",
      "\t\n",
      "\t# Done looping through phonemes. We may have consonants left at the end.\n",
      "\t# We may have even not found a nucleus.\n",
      "\tif len(internuclei) > 0 :\n",
      "\t\tif len(syllables) == 0 :\n",
      "\t\t\tsyllables.append( (None, internuclei, [], []) )\n",
      "\t\telse :\n",
      "\t\t\tsyllables[-1][3].extend(internuclei)\n",
      "\n",
      "\treturn syllables\n",
      "\n",
      "def stringify(syllables) :\n",
      "\t'''This function takes a syllabification returned by syllabify and\n",
      "\t   turns it into a string, with phonemes spearated by spaces and\n",
      "\t   syllables spearated by periods.'''\n",
      "\tret = []\n",
      "\tfor syl in syllables :\n",
      "\t\tstress, onset, nucleus, coda = syl\n",
      "\t\tif stress != None and len(nucleus) != 0 :\n",
      "\t\t\tnucleus[0] += str(stress)\n",
      "\t\tret.append(\" \".join(onset + nucleus + coda))\n",
      "\treturn \" . \".join(ret)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def expand_dictionary(food_words):\n",
      "    full_food_words = set()\n",
      "    \n",
      "    lemmatizer = nltk.WordNetLemmatizer()\n",
      "    \n",
      "    for f in food_words:\n",
      "        full_food_words.add(f)\n",
      "        full_food_words.add(lemmatizer.lemmatize(f))\n",
      "    return sorted(list(full_food_words))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arpabet = nltk.corpus.cmudict.dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 1. Get food words\n",
      "# Food url is http://www.food.com/library/all.zsp\n",
      "def get_food_data():\n",
      "    f = urllib2.urlopen('http://www.food.com/library/all.zsp')\n",
      "    raw_food_data = BeautifulSoup.BeautifulSoup(f)\n",
      "    f.close()\n",
      "    return raw_food_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_foods(raw_data):\n",
      "    content = raw_data.findAll('div', 'content')[0]\n",
      "    return expand_dictionary([item.findAll('a')[0]['title'].lower() for item in content.findAll('li')])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def analyze_rhyme(phonemes):\n",
      "    ''' Returns the stress pattern, and the rhyme scheme of the last syllable '''\n",
      "    syllables = syllabify(English, ' '.join(phonemes))\n",
      "    \n",
      "    stresses = [int(x[0]>0) for x in syllables]\n",
      "    tail     = filter(lambda x: len(x) > 0, syllables[-1][1:])\n",
      "    \n",
      "    # Crunch the tail?\n",
      "    # Only if the last phoneme is a vowel and the first is a consonant\n",
      "    if ' '.join(tail[0]) in English['onsets'] and ''.join(tail[-1]) not in English['vowels']:\n",
      "        tail = tail[1:]\n",
      "    \n",
      "    _tail = []\n",
      "    for t in tail:\n",
      "        _tail.extend(t)\n",
      "    return stresses, _tail"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use the P2TK syllabifier\n",
      "# Count syllables in each word\n",
      "# word => (tail, # syllables)\n",
      "# 'tail' is the last syllable minus the onset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 211
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_food_data = get_food_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "food_strings = get_foods(raw_food_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# stress -> ending -> list of words\n",
      "food_mapping = {}\n",
      "for s in food_strings:\n",
      "    # tokenize s\n",
      "    #s = nltk.tokenize.word_tokenize(s)\n",
      "    \n",
      "    if s in arpabet:\n",
      "        for p in arpabet[s]:\n",
      "            stresses, tail = analyze_rhyme(p)\n",
      "            key_str = ''.join(map(str, stresses))\n",
      "            key_end = '_'.join(tail)\n",
      "            \n",
      "            if key_str not in food_mapping:\n",
      "                food_mapping[key_str] = {}\n",
      "                \n",
      "            if key_end not in food_mapping[key_str]:\n",
      "                food_mapping[key_str][key_end] = set()\n",
      "                \n",
      "            food_mapping[key_str][key_end].add(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3. Build a query interface\n",
      "def rhyme_searcher(mapping, query):\n",
      "    query = query.lower()\n",
      "    \n",
      "    results = set()\n",
      "    if query in arpabet:\n",
      "        for p in arpabet[query]:\n",
      "            stresses, tail = analyze_rhyme(p)\n",
      "            key_str = ''.join(map(str, stresses))\n",
      "            key_end = '_'.join(tail)\n",
      "    \n",
      "            if key_str in mapping:\n",
      "                if key_end in mapping[key_str]:\n",
      "                    results.update(mapping[key_str][key_end])\n",
      "                    \n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def string_query(food_mapping, query):\n",
      "    \n",
      "    # Tokenize the query\n",
      "    tokens = nltk.tokenize.word_tokenize(query)\n",
      "    \n",
      "    # Part-of-speech tag\n",
      "    tags = nltk.pos_tag(tokens)\n",
      "    \n",
      "    results = set()\n",
      "    \n",
      "    for word in filter(lambda x: x[-1][0] == 'N', tags):\n",
      "        \n",
      "        replacements = rhyme_searcher(food_mapping, word[0])\n",
      "        \n",
      "        if len(replacements) == 0:\n",
      "            continue\n",
      "        \n",
      "        for r in replacements:\n",
      "            results.add(query.replace(word[0], r))\n",
      "            \n",
      "    # Return everything except the original query\n",
      "    return sorted(list(results - set([query])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Save the language and dictionary files\n",
      "with open('/home/bmcfee/git/musichacks/2013.12/data/model.pickle', 'w') as f:\n",
      "    pickle.dump([English, food_mapping], f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 293
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "string_query(food_mapping, \"welcome to the jungle\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 338,
       "text": [
        "[u'alum to the jungle',\n",
        " u'edam to the jungle',\n",
        " u'sorghum to the jungle',\n",
        " u'welcome to the apple',\n",
        " u'welcome to the bagel',\n",
        " u'welcome to the basil',\n",
        " u'welcome to the fennel',\n",
        " u'welcome to the kugel',\n",
        " u'welcome to the lentil',\n",
        " u'welcome to the muddle',\n",
        " u'welcome to the mussel',\n",
        " u'welcome to the pickle',\n",
        " u'welcome to the sorrel',\n",
        " u'welcome to the truffle',\n",
        " u'welcome to the turtle']"
       ]
      }
     ],
     "prompt_number": 338
    }
   ],
   "metadata": {}
  }
 ]
}